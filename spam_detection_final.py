"""
–¢”®–°–õ–ò–ô–ù –ê–ñ–ò–õ: –ò–ú–≠–ô–õ –°–ü–ê–ú –ò–õ–†“Æ“Æ–õ–≠–• –°–ò–°–¢–ï–ú

–ó–û–†–ò–õ–ì–û: –ò–º—ç–π–ª –º–µ—Å—Å–µ–∂“Ø“Ø–¥–∏–π–≥ —Å–ø–∞–º —ç—Å–≤—ç–ª —Ö—ç–≤–∏–π–Ω –≥—ç–∂ –∞–Ω–≥–∏–ª–∞—Ö
–ó–ê–ì–í–ê–†–£–£–î: Naive Bayes, Decision Tree, Logistic Regression

”®–ì”®–ì–î–õ–ò–ô–ù –≠–• –°–£–†–í–ê–õ–ñ:
- Dataset: spam_dataset.csv
- –¢–∞–π–ª–±–∞—Ä: message_content (–∏–º—ç–π–ª–∏–π–Ω —Ç–µ–∫—Å—Ç), is_spam (0=—Ö—ç–≤–∏–π–Ω, 1=—Å–ø–∞–º)
- –≠—Ö —Å—É—Ä–≤–∞–ª–∂: Synthetic Email Spam Dataset / Educational Use
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string
import time
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                             f1_score, confusion_matrix, classification_report)
import joblib
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.sans-serif'] = ['Arial']

print("–ò–ú–≠–ô–õ –°–ü–ê–ú –ò–õ–†“Æ“Æ–õ–≠–• –°–ò–°–¢–ï–ú")

# 1. ”®–ì”®–ì–î”®–õ –£–ù–®–ò–ñ –ê–í–ê–•
print("\n1. ”®–≥”©–≥–¥”©–ª —É–Ω—à–∏–∂ –±–∞–π–Ω–∞...")
df = pd.read_csv('spam_dataset.csv')
print(f"   –ù–∏–π—Ç: {len(df)} –º”©—Ä, {df.shape[1]} –±–∞–≥–∞–Ω–∞")
print(f"   Missing values: {df.isnull().sum().sum()}")
print(f"   –•—ç–≤–∏–π–Ω: {(df['is_spam']==0).sum()}, –°–ø–∞–º: {(df['is_spam']==1).sum()}")

# 2. –¢–ï–ö–°–¢ –¶–≠–í–≠–†–õ–≠–•
print("\n2. –¢–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç–∂ –±–∞–π–Ω–∞...")

def clean_text(text):
    """–¢–µ–∫—Å—Ç–∏–π–≥ —Ü—ç–≤—ç—Ä–ª—ç—Ö: lowercase, —Ç–æ–æ/—Ç—É—Å–≥–∞–π —Ç—ç–º–¥—ç–≥—Ç —É—Å—Ç–≥–∞—Ö"""
    text = text.lower()
    text = re.sub(r'\d+', '', text)
    text = text.translate(str.maketrans('', '', string.punctuation))
    return ' '.join(text.split())

df['message_clean'] = df['message_content'].apply(clean_text)
print(f"   ‚úì –¢–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç–≥–¥—Å—ç–Ω")

# 3. ”®–ì”®–ì–î”®–õ –•–£–í–ê–ê–•
print("\n3. ”®–≥”©–≥–¥”©–ª —Ö—É–≤–∞–∞—Ä–∏–ª–∂ –±–∞–π–Ω–∞...")
X = df['message_clean']
y = df['is_spam']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(f"   –°—É—Ä–≥–∞–ª—Ç: {len(X_train)}, –¢–µ—Å—Ç: {len(X_test)}")

# 4. TF-IDF –í–ï–ö–¢–û–†–ñ–£–£–õ–ê–õ–¢
print("\n4. TF-IDF –≤–µ–∫—Ç–æ—Ä–∂—É—É–ª–∞–ª—Ç —Ö–∏–π–∂ –±–∞–π–Ω–∞...")
vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
X_train_tfidf = vectorizer.fit_transform(X_train)  # fit –∑”©–≤—Ö”©–Ω —Å—É—Ä–≥–∞–ª—Ç –¥—ç—ç—Ä
X_test_tfidf = vectorizer.transform(X_test)
print(f"   ‚úì –ú–∞—Ç—Ä–∏—Ü: {X_train_tfidf.shape}")

# 5. –ó–ê–ì–í–ê–†–£–£–î–´–ì –°–£–†–ì–ê–•
print("\n5. –ó–∞–≥–≤–∞—Ä—É—É–¥—ã–≥ —Å—É—Ä–≥–∞–∂ –±–∞–π–Ω–∞...")
results = {}
models = {}

# 5.1 Naive Bayes
print("   5.1 Naive Bayes...")
train_start = time.time()
nb_grid = GridSearchCV(MultinomialNB(), {'alpha': [0.1, 0.5, 1.0]}, 
                       cv=5, scoring='f1')
nb_grid.fit(X_train_tfidf, y_train)
nb_model = nb_grid.best_estimator_
train_time = time.time() - train_start

pred_start = time.time()
nb_pred = nb_model.predict(X_test_tfidf)
pred_time = time.time() - pred_start

results['Naive Bayes'] = {
    'accuracy': accuracy_score(y_test, nb_pred),
    'precision': precision_score(y_test, nb_pred),
    'recall': recall_score(y_test, nb_pred),
    'f1_score': f1_score(y_test, nb_pred),
    'predictions': nb_pred,
    'train_time': train_time,
    'pred_time': pred_time
}
models['Naive Bayes'] = nb_model
print(f"       Accuracy: {results['Naive Bayes']['accuracy']:.4f}, "
      f"F1: {results['Naive Bayes']['f1_score']:.4f}, "
      f"–•—É—Ä–¥: {pred_time*1000:.2f}ms")

# 5.2 Decision Tree
print("   5.2 Decision Tree...")
train_start = time.time()
dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), 
                       {'max_depth': [5, 10, 15]}, cv=5, scoring='f1')
dt_grid.fit(X_train_tfidf, y_train)
dt_model = dt_grid.best_estimator_
train_time = time.time() - train_start

pred_start = time.time()
dt_pred = dt_model.predict(X_test_tfidf)
pred_time = time.time() - pred_start

results['Decision Tree'] = {
    'accuracy': accuracy_score(y_test, dt_pred),
    'precision': precision_score(y_test, dt_pred),
    'recall': recall_score(y_test, dt_pred),
    'f1_score': f1_score(y_test, dt_pred),
    'predictions': dt_pred,
    'train_time': train_time,
    'pred_time': pred_time
}
models['Decision Tree'] = dt_model
print(f"       Accuracy: {results['Decision Tree']['accuracy']:.4f}, "
      f"F1: {results['Decision Tree']['f1_score']:.4f}, "
      f"–•—É—Ä–¥: {pred_time*1000:.2f}ms")

# 5.3 Logistic Regression
print("   5.3 Logistic Regression...")
train_start = time.time()
lr_grid = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), 
                       {'C': [0.1, 1.0, 10.0]}, cv=5, scoring='f1')
lr_grid.fit(X_train_tfidf, y_train)
lr_model = lr_grid.best_estimator_
train_time = time.time() - train_start

pred_start = time.time()
lr_pred = lr_model.predict(X_test_tfidf)
pred_time = time.time() - pred_start

results['Logistic Regression'] = {
    'accuracy': accuracy_score(y_test, lr_pred),
    'precision': precision_score(y_test, lr_pred),
    'recall': recall_score(y_test, lr_pred),
    'f1_score': f1_score(y_test, lr_pred),
    'predictions': lr_pred,
    'train_time': train_time,
    'pred_time': pred_time
}
models['Logistic Regression'] = lr_model
print(f"       Accuracy: {results['Logistic Regression']['accuracy']:.4f}, "
      f"F1: {results['Logistic Regression']['f1_score']:.4f}, "
      f"–•—É—Ä–¥: {pred_time*1000:.2f}ms")

# 6. “Æ–† –î“Æ–ù–ì –•–ê–†–¨–¶–£–£–õ–ê–•
print("\n6. “Æ—Ä –¥“Ø–Ω–≥ —Ö–∞—Ä—å—Ü—É—É–ª–∂ –±–∞–π–Ω–∞...")
results_df = pd.DataFrame(results).T
print("\n" + str(results_df[['accuracy', 'precision', 'recall', 'f1_score']].round(4)))

print("\n  –•–£–†–î–ù–´ –•–ê–†–¨–¶–£–£–õ–ê–õ–¢:")
print(f"{'–ó–∞–≥–≤–∞—Ä':<20} {'–°—É—Ä–≥–∞–ª—Ç (—Å–µ–∫)':<15} {'–¢–∞–∞–º–∞–≥–ª–∞–ª (ms)':<15}")
print("-" * 50)
for model_name in results.keys():
    train_t = results[model_name]['train_time']
    pred_t = results[model_name]['pred_time'] * 1000
    print(f"{model_name:<20} {train_t:<15.3f} {pred_t:<15.2f}")

fastest_model = min(results.keys(), key=lambda x: results[x]['pred_time'])
print(f"\n‚ö° –•–∞–º–≥–∏–π–Ω —Ö—É—Ä–¥–∞–Ω: {fastest_model} "
      f"({results[fastest_model]['pred_time']*1000:.2f}ms)")

best_model_name = results_df['f1_score'].idxmax()
print(f"üèÜ –•–∞–º–≥–∏–π–Ω —Å–∞–π–Ω F1: {best_model_name} "
      f"(F1={results_df['f1_score'].max():.4f})")

# 7. –î–≠–õ–ì–≠–†–≠–ù–ì“Æ–ô –¢–ê–ô–õ–ê–ù
print("\n7. –î—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π —Ç–∞–π–ª–∞–Ω:")
best_pred = results[best_model_name]['predictions']
print(f"\nClassification Report ({best_model_name}):")
print(classification_report(y_test, best_pred, target_names=['–•—ç–≤–∏–π–Ω', '–°–ø–∞–º']))

cm = confusion_matrix(y_test, best_pred)
print(f"Confusion Matrix:\n{cm}")
print(f"–ó”©–≤ —Ç–∞–∞—Å–∞–Ω: {cm[0][0]+cm[1][1]}/{len(y_test)}")

# 8. –ì–†–ê–§–ò–ö –ó–£–†–ê–•
print("\n8. –ì—Ä–∞—Ñ–∏–∫ –∑—É—Ä–∂ –±–∞–π–Ω–∞...")
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Accuracy —Ö–∞—Ä—å—Ü—É—É–ª–∞–ª—Ç
ax1 = axes[0, 0]
model_names = list(results.keys())
accuracies = [results[m]['accuracy'] for m in model_names]
bars = ax1.bar(model_names, accuracies, color=['#3498db', '#e74c3c', '#2ecc71'], 
               alpha=0.7, edgecolor='black')
ax1.set_ylabel('Accuracy')
ax1.set_title('–ó–∞–≥–≤–∞—Ä—É—É–¥—ã–Ω –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª', fontweight='bold')
ax1.set_ylim([0.95, 1.0])
ax1.grid(axis='y', alpha=0.3)
for bar in bars:
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height,
             f'{height:.3f}', ha='center', va='bottom')

# –ë“Ø—Ö –º–µ—Ç—Ä–∏–∫
ax2 = axes[0, 1]
metrics = ['accuracy', 'precision', 'recall', 'f1_score']
x = np.arange(len(model_names))
width = 0.2
for i, metric in enumerate(metrics):
    values = [results[m][metric] for m in model_names]
    ax2.bar(x + i*width, values, width, label=metric.capitalize(), alpha=0.8)
ax2.set_ylabel('–£—Ç–≥–∞')
ax2.set_title('–ë“Ø—Ö –º–µ—Ç—Ä–∏–∫“Ø“Ø–¥', fontweight='bold')
ax2.set_xticks(x + width * 1.5)
ax2.set_xticklabels(model_names, rotation=15, ha='right')
ax2.legend(fontsize=8)
ax2.grid(axis='y', alpha=0.3)
ax2.set_ylim([0.95, 1.0])

# Confusion Matrix
ax3 = axes[1, 0]
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, ax=ax3,
            xticklabels=['–•—ç–≤–∏–π–Ω', '–°–ø–∞–º'], yticklabels=['–•—ç–≤–∏–π–Ω', '–°–ø–∞–º'])
ax3.set_ylabel('–ë–æ–¥–∏—Ç —É—Ç–≥–∞')
ax3.set_xlabel('–¢–∞–∞–º–∞–≥–ª–∞—Å–∞–Ω —É—Ç–≥–∞')
ax3.set_title(f'Confusion Matrix ({best_model_name})', fontweight='bold')

# ”®–≥”©–≥–¥–ª–∏–π–Ω —Ö–∞—Ä—å—Ü–∞–∞
ax4 = axes[1, 1]
spam_counts = df['is_spam'].value_counts()
ax4.pie(spam_counts, labels=['–•—ç–≤–∏–π–Ω', '–°–ø–∞–º'], 
        colors=['#2ecc71', '#e74c3c'], autopct='%1.1f%%', startangle=90)
ax4.set_title('”®–≥”©–≥–¥–ª–∏–π–Ω —Ö–∞—Ä—å—Ü–∞–∞', fontweight='bold')

plt.suptitle('–ò–º—ç–π–ª –°–ø–∞–º –ò–ª—Ä“Ø“Ø–ª—ç—Ö “Æ—Ä –î“Ø–Ω', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig('spam_results.png', dpi=300, bbox_inches='tight')
print("   ‚úì –ì—Ä–∞—Ñ–∏–∫ —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞: spam_results.png")

# 9. –ó–ê–ì–í–ê–†–£–£–î–´–ì –•–ê–î–ì–ê–õ–ê–•
print("\n9. –ó–∞–≥–≤–∞—Ä—É—É–¥—ã–≥ —Ö–∞–¥–≥–∞–ª–∂ –±–∞–π–Ω–∞...")
joblib.dump(vectorizer, 'vectorizer.joblib')
for name, model in models.items():
    filename = f"{name.lower().replace(' ', '_')}.joblib"
    joblib.dump(model, filename)
print("   ‚úì –ë“Ø—Ö –∑–∞–≥–≤–∞—Ä —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞")

# 10. –®–ò–ù–≠ –ò–ú–≠–ô–õ –¢–ï–°–¢
print("\n10. –®–∏–Ω—ç –∏–º—ç–π–ª —Ç–µ—Å—Ç —Ö–∏–π–∂ –±–∞–π–Ω–∞...")
test_emails = [
    "Hello, meeting reminder for tomorrow at 10 AM.",
    "Congratulations! You won $1000000! Click now!",
    "Please review the attached document.",
    "FREE MONEY!!! Act now! Limited offer!"
]

best_model = models[best_model_name]
for i, email in enumerate(test_emails, 1):
    email_clean = clean_text(email)
    email_tfidf = vectorizer.transform([email_clean])
    prediction = best_model.predict(email_tfidf)[0]
    probability = best_model.predict_proba(email_tfidf)[0]
    
    print(f"\n   –ò–º—ç–π–ª #{i}: {email[:50]}...")
    print(f"   –¢–∞–∞–º–∞–≥–ª–∞–ª: {'üö´ –°–ü–ê–ú' if prediction == 1 else '‚úÖ –•–≠–í–ò–ô–ù'} "
          f"(–°–ø–∞–º: {probability[1]:.1%})")

# –î“Æ–ì–ù–≠–õ–¢
print("\n" + "="*70)
print("–î“Æ–ì–ù–≠–õ–¢")
print("="*70)
print(f"‚úì ”®–≥”©–≥–¥”©–ª: {len(df)} –∏–º—ç–π–ª ({(df['is_spam']==0).sum()} —Ö—ç–≤–∏–π–Ω, "
      f"{(df['is_spam']==1).sum()} —Å–ø–∞–º)")
print(f"‚úì Preprocessing: –¢–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç–ª—Ç, TF-IDF –≤–µ–∫—Ç–æ—Ä–∂—É—É–ª–∞–ª—Ç")
print(f"‚úì –ó–∞–≥–≤–∞—Ä—É—É–¥: Naive Bayes, Decision Tree, Logistic Regression")
print(f"‚úì Hyperparameter tuning: GridSearchCV + 5-fold CV")
print(f"‚úì –•–∞–º–≥–∏–π–Ω —Å–∞–π–Ω: {best_model_name} (Accuracy: "
      f"{results_df['accuracy'].max()*100:.2f}%)")
print(f"‚úì –ë“Ø—Ö –∑–∞–≥–≤–∞—Ä ”©–Ω–¥”©—Ä –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—Ç–∞–π –∞–∂–∏–ª–ª–∞—Å–∞–Ω")
print("\nüìÅ –§–∞–π–ª—É—É–¥: spam_results.png, vectorizer.joblib, –∑–∞–≥–≤–∞—Ä—É—É–¥—ã–Ω .joblib")
print("="*70)
